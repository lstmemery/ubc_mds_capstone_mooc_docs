[
["index.html", "edXviz: Interactive Visualization of Student Engagement with edX MOOCs 1 Overview of the Project 1.1 Introduction 1.2 Availability of Data 1.3 Contents of this Document 1.4 Acknowledgments 1.5 Instructions for generating this bookdown document", " edXviz: Interactive Visualization of Student Engagement with edX MOOCs Matt Emery, David Laing, Andrew Lim, Subi Zhang 2017-06-23 1 Overview of the Project 1.1 Introduction edXviz is a capstone project completed by Matthew Emery, David Laing, Andrew Lim, and Subi Zhang, in partial fulfillment of the degree requirements for the Master of Data Science at the University of British Columbia (UBC). The project was completed in partnership with the Centre for Teaching, Learning and Technology (CTLT) at UBC. Hundreds of thousands of students worldwide are enrolled in UBC’s many massive open online courses (MOOCs). These MOOCs generate huge amounts of data, much of which could be used to help instructors understand how students are engaging with their courses. For our capstone project, we built a dashboard that is accessible to MOOC instructors directly in their edX course website. The dashboard will help instructors to discover patterns across the structures of their courses, with a special focus on course elements where student engagement is especially high or low. The dashboard includes visualizations of how students are interacting with course content such as videos and pages, how they are performing on problem sets, and how they are behaving in the discussion forums. edXviz is available as an open-source R package, and development is ongoing. 1.2 Availability of Data All of the data used in this project is stored in Google BigQuery. Most of it is in relational tables, although some is in other file formats. See below for an overview of the main script that is used to acquire and prepare the data for loading into the dashboard: The python script populate_courses.py will acquire and process all the data for a user-defined list of courses. For each course, the bash script populate_course.sh is called. populate_course.sh calls the python script rbq.py sixteen times, each with a different SQL script as an argument, as well as download_gcp_material.sh, which downloads a JSON file and an XML file. populate_course.sh then calls six R scripts, each of which wrangles the data for one of the six views of the dashboard. The dashboard itself is a modularized R Shiny app, which is intended to be hosted on Microsoft Azure in a Docker container. 1.3 Contents of this Document The edXviz dashboard has six separate views, each of which shows a different type of data: Engagement Overview (or “Eiffel Tower” plot) General Demographics Links and Pages Discussion Forum Problems Videos This document devotes two sections to each of the views. In each view’s first section, we describe the data preparation process in greater detail, and provide explanations of each of the visualizations. In each view’s second section, we provide standard R documentation for the functions that were used to wrangle that data and serve it in the Shiny app. Finally, we provide a step-by-step guide for deploying the app on Microsoft Azure. 1.4 Acknowledgments We are grateful to many of our colleagues at UBC. Especially, we are grateful to our capstone partners, Ido Roll and Sarah Perez, who came up with the project and were extremely generous with their time, energy, feedback, and support. We are also grateful to our mentor in the Master of Data Science program, Giulio Valentina Dalla Riva, whose advice was invaluable. Lastly, we are grateful to the many people who provided valuable feedback throughout our development process, including Leah Macfadyen, Letitia Englund, Derek White, Scott McMillan, Pan Luo, Sanam Shirazi, Giuseppe Carenini, Manuel Dias, Jason Myers, Raeanne Lee, Sazi Valair, Erika Thompson, Patrick Dubois, Aviv Milner, and others. 1.5 Instructions for generating this bookdown document Navigate to the edx_viz_documentation directory in our capstone repository, and run the following code in R: bookdown::render_book(&#39;index.Rmd&#39;, &#39;all&#39;) "],
["engagement-overview-dashboard-overview.html", "2 Engagement Overview Dashboard Overview 2.1 Data Cleaning Pipeline 2.2 Visualization Reasoning and Caveats", " 2 Engagement Overview Dashboard Overview 2.1 Data Cleaning Pipeline 2.2 Visualization Reasoning and Caveats Since videos and problems are the two basic components in edX MOOC courses, instructors can get a general picture concerning student engagement by seeing how many students engaged with each video/problem. As a result, we designed this the plot below to show the relationship between course structure and engagement. Each horizontal bar is a course element (video, problem or module separator). These bars are arranged in such a way that matches its occurrence within the course. The length of each bar indicates how many student engaged with this course element. This visualization aims to help instructors finish four types of tasks: Obtain an intuitive sense about course structure. For example, instructors can explore which module are relatively excessive and contain an abnormally high amount of course elements. Identify where students drop out of the course. Locate videos and problems throughout the course by using module filtering Explore trends amongst the learners by applying different filtering options. For example, instructors may explore engagement differences between auditing and verified students. "],
["engagement-overview-dashboard-functions.html", "3 Engagement Overview Dashboard Functions 3.1 Wrangling Functions 3.2 Server Functions", " 3 Engagement Overview Dashboard Functions 3.1 Wrangling Functions 3.1.1 read_dirt_engagement_data Import untidy student engagement csv file as an R dataframe object Description: Import untidy student engagement csv file as an R dataframe object Usage: read_dirt_engagement_data(input_course) Arguments: input_course: Name of course directory (ex. psyc1, spd1, marketing, etc) Value: tower_engage: Dataframe containing student engagement information with videos and problems Examples: read_dirt_engagement_data(input_course = &#39;psyc1&#39;) 3.1.2 clean_engagement_data Remove initial messy strings in module_id column and rename mode column Description: Remove initial messy strings in module_id column and rename mode column Usage: clean_engagement_data(dirt_engagement_data) Arguments: dirt_engagement_data: tower_engage_dirt dataframe object Value: dirt_engagement_data : tidy dataframe adter wrangling Examples: clean_engagement_data(dirt_engagement_data = obtain_dirt_engagement_data) 3.1.3 write_tidy_engagement_data Write cleaned data as a csv into the specified course directory Description: Write cleaned data as a csv into the specified course directory Usage: write_tidy_engagement_data(input_course, cleaned_data) Arguments: input_course: Name of course directory (ex. psyc1, spd1, marketing, etc) cleaned_data: Dataframe containing cleaned data. Examples: write_tidy_engagement_data(input_course = &#39;psyc1&#39;, cleaned_data = clean_engagement_data) 3.1.4 wrangle_overview_engagement This function automatically reads a file named &quot;tower_engage_dirt.csv&quot; from the specified course directory and output a clean files named &quot;tower_engage.csv&quot; in the same directory Description: This function automatically reads a file named &quot;tower_engage_dirt.csv&quot; from the specified course directory and output a clean files named &quot;tower_engage.csv&quot; in the same directory Usage: wrangle_overview_engagement(input_course) Arguments: input_course: String of course directory name Examples: wrangle_video(input_course = &quot;psyc1&quot;) 3.2 Server Functions 3.2.1 filter_chapter_overview Filter course items dataframe by the selected course module Description: Filter course items dataframe by the selected course module Usage: filter_chapter_overview(input_df, module = &quot;All&quot;) Arguments: module: One of the modules of the course item_df: The course items dataframe. Value: A dataframe filtered by the selected course module Examples: filter_chapter_overview(tower_item, &quot;all&quot;) 3.2.2 get_module_vector Create a module name vector sorted by the course structure index. This vector is used in the module filtering select box in ui.R Description: Create a module name vector sorted by the course structure index. This vector is used in the module filtering select box in ui.R Create a module name vector sorted by the course structure index.This vector is used in the module filtering select box in ui.R Usage: get_module_vector(item_df) get_module_vector(item_df) Arguments: item_df: item_df: The course axis dataframe Value: chap_name chap_name A vector containg all unique module names. Examples: get_module_vector(item_df = tower_item) 3.2.3 create_module_name Create a new column &quot;chapter_name&quot; for course item dataframe in order to implement module filtering Description: Create a new column &quot;chapter_name&quot; for course item dataframe in order to implement module filtering Usage: create_module_name(item_df) Arguments: item_df: A course axis dataframe only containing item name Value: item_df A coure axis dataframe adding chapter_name column Examples: create_module_name(item_df = tower_item) 3.2.4 get_nactive Compute how many students engaged with each course item after filtering student demographic Description: Compute how many students engaged with each course item after filtering student demographic Usage: get_nactive(detail_df) Arguments: detail_df: Filtered student engagement dataframe Value: summary_df Summarized-view of engagement dataframe. Examples: get_nactive(detail_df = tower_engage) 3.2.5 join_engagement_item Join filtered summary engagement dataframe with filtered item dataframe to match &quot;item &quot; ,&quot;item name&quot; and &quot;nactive&quot; convert all module item nacitve number to a constant to draw seperator line later Description: Join filtered summary engagement dataframe with filtered item dataframe to match &quot;item &quot; ,&quot;item name&quot; and &quot;nactive&quot; convert all module item nacitve number to a constant to draw seperator line later Usage: join_engagement_item(filtered_engagement, filtered_item) Arguments: filtered_engagement: Filtered engagement dataframe. filtered_item: Filtered course axis dataframe Value: tower_df Dataframe containing item name, item category and how many student engaged with it Examples: join_engagement_item(filtered_engagement = filtered_tower_engage,filtered_item = filtered_tower_item) 3.2.6 get_module_nactive Count how many filtered students engaged with the filtered course module Description: Count how many filtered students engaged with the filtered course module Usage: get_module_nactive(tower_df) Arguments: tower_df: Student engagement dataframe. Value: student_num A number refers to the maximum number of student engaged with one item witin the selected course module. Examples: get_module_nactive(reactive_tower_df()) 3.2.7 make_engagement_eiffel_tower Make effiel tower plot : all video/problem course items vs. number of engaging student Description: Make effiel tower plot : all video/problem course items vs. number of engaging student Usage: make_engagement_eiffel_tower(tower_data) Arguments: tower_data: Examples: make_engagement_eiffel_tower(tower_data = reactive_tower_df()) "],
["general-demographics-overview.html", "4 General Demographics Overview 4.1 Data Cleaning Pipeline 4.2 Visualization Reasoning and Caveats:", " 4 General Demographics Overview 4.1 Data Cleaning Pipeline The figure above shows the data cleaning pipeline for demographics data. Raw student demographics data is initially stored in Google BigQuery. It is downloaded and cleaned programatically through the populate_courses.py script. Next, the cleaned wrangle_demographics.csv file is used to generate the video visualizations. It should be noted that the data obtained through the use of generalized_demographics.sql and rbq.py is not the entire dataset of students. Instead, only students with a known IP address are obtained. This was done because IP address is used to infer statistics such as country and language. Please see generalized_demographics.sql for details. 4.2 Visualization Reasoning and Caveats: In this section, we show visualizations included within our video dashboard. Additionally, the reasoning that went into their design as well as the caveats that go along with those decisions are provided. The plot above shows the level of education of the students. This is obtained from the LoE variable within the person_course table found on Google BigQuery. In order to transform the level of education code to its actual human readable format such as “Doctorate” or “High School”, the function convert_loe is used. This function assumes that the codes of “p”, “p_se”, and “p_oth” all refer to PhD which translates to a level of education of “Doctorate” in the visualization above. This assumption may not be entirely correct but are based off of the options available on EdX account profiles: The plot above shows the top ten countries according to the number of students enrolled. Student’s country is inferred from their IP addresses within the variable cc_by_ip. This was done because the variable countryLabel available in the person_course BigQuery table is relatively sparse compared to cc_by_ip. The plot above shows the top ten languages according to the number of students that speak it. The students’ language is inferred from their country which is in turn, inferred from their IP address. This was done because the language variable within the person_course table in BigQuery was obtained through their modal video transcripts. The original language variable seemed very biased towards English and as a result, the the students’ language was chosen to be inferred from their country. The plot above shows the distribution of ages amongst the learners. It should be noted that all ages less than 5 and greater than 100 have been filtered out. This was done because their are often fake accounts that entered a year of birth such that their age would be 200 or greater. As a result, the histogram would be difficult to read. The thresholds of 5 and 100 can be adjusted through the constants MIN_AGE and MAX_AGE found within the general_server.R file. Developer Note: The global constants should be transitioned into arguments passed into the get_age_plot function within the general_server.R file. "],
["general-demographics-dashboard-functions.html", "5 General Demographics Dashboard Functions 5.1 Wrangling Functions 5.2 Server Functions", " 5 General Demographics Dashboard Functions 5.1 Wrangling Functions 5.1.1 wrangle_general 5.1.1.1 Main Documentation Wrangles raw general demographics data Description: Reads the input course&#39;s raw &#39;generalized_demographics.csv&#39; and outputs a cleaned version as wrangled_demographics.csv within the same directory Usage: wrangle_general(input_course) Arguments: input_course: String value of input course short name Value: No value is returned Examples: wrangle_general(&#39;psyc1&#39;) 5.1.2 obtain_raw_general_data 5.1.2.1 Main Documentation Obtains raw general demographic data Description: Obtains raw general demographic data Usage: obtain_raw_general_data(input_course) Arguments: input_course: String value of input course short name Value: Returns a data frame with the raw general demographic data Examples: obtain_raw_general_data(&#39;psyc1&#39;) 5.1.3 obtain_language_info 5.1.3.1 Main Documentation Obtains a data frame with language information Description: Reads in a .csv containing languages and their ISO code. Usage: obtain_language_info() Value: Returns a data frame with languages and their corresponding ISO codes Examples: obtain_language_info() 5.1.4 obtain_country_info 5.1.4.1 Main Documentation Obtains a data frame with countries and ISO codes of their associated languages Description: Obtains a data frame with countries and ISO codes of their associated languages Usage: obtain_country_info() Value: Data frame with countries and their associated ISO language codes Examples: obtain_country_info() 5.1.5 prepare_general_data 5.1.5.1 Main Documentation Cleans raw demographic data Description: Cleans raw demographic data Usage: prepare_general_data(data, language_info, country_info) Arguments: data: Data frame containing student demographic information language_info: Data frame containing languages and their associated ISO codes country_info: Data frame with countries and their associated languages as ISO codes Value: Cleaned data frame containing demographic information Examples: prepare_general_data(obtain_raw_general_data(&#39;psyc1&#39;), language_info(), country_info()) 5.1.6 write_general_data 5.1.6.1 Main Documentation Writes cleaned demographic data frame as a .csv to the specified course Description: Writes cleaned demographic data frame as a .csv to the specified course Usage: write_general_data(input_course, data) Arguments: input_course: String value of course short name data: The data frame containing cleaned demographic data Value: No value is returned Examples: write_general_data(&#39;psyc1&#39;, cleaned_demographic_data) 5.2 Server Functions 5.2.1 convert_loe 5.2.1.1 Main Documentation Converts level of education code to explicit string Description: Converts level of education code to explicit string Usage: convert_loe(LoE) Arguments: LoE: String value of level of education code Value: Returns explicit string value of level of education 5.2.2 get_loe_df 5.2.2.1 Main Documentation Returns aggregated level of education data frame Description: Returns aggregated level of education data frame Usage: get_loe_df(data) Arguments: data: Data frame containing explicit level of education of students Value: Data frame containing aggregated level of education 5.2.3 get_loe_plot 5.2.3.1 Main Documentation Returns plot with level of education of students Description: Returns plot with level of education of students Usage: get_loe_plot(loe_df) Arguments: loe_df: Data frame containing studentes aggregated by level of education Value: Returns a ggplot geom_bar object 5.2.4 get_age_df 5.2.4.1 Main Documentation Returns dataframe with student&#39;s ages Description: Returns dataframe with student&#39;s ages Usage: get_age_df(data) Arguments: data: Dataframe containing year of birth Value: Returns a dataframe with student&#39;s ages 5.2.5 get_age_plot 5.2.5.1 Main Documentation Returns histogram plot of student&#39;s age Description: Returns histogram plot of student&#39;s age Usage: get_age_plot(age_df) Arguments: age_df: Data frame containing age of students Value: Returns a ggplot geom_histogram object 5.2.6 get_top_country_df 5.2.6.1 Main Documentation Returns country aggregated data frame Description: Returns country aggregated data frame Usage: get_top_country_df(data, top_selection) Arguments: data: Data frame containing students&#39; country top_selection: The number of countries to include in output data frame Value: A data frame containing countries with the most number of students 5.2.7 get_country_plot 5.2.7.1 Main Documentation Returns a plot containing student country distribution Description: Returns a plot containing student country distribution Usage: get_country_plot(country_df, top_selection) Arguments: country_df: Data frame of students aggregated by country top_selection: The number of countries to include in the plot Value: Returns a ggplot geom_bar object 5.2.8 get_top_language_df 5.2.8.1 Main Documentation Returns a language aggregated data frame Description: Returns a language aggregated data frame Usage: get_top_language_df(data, top_selection) Arguments: data: Data frame containing student language information top_selection: Number of languages to include within the data frame Value: A data frame containing languages with the most number of students who speak it 5.2.9 get_language_plot 5.2.9.1 Main Documentation Returns plot of language aggregated information Description: Returns plot of language aggregated information Usage: get_language_plot(language_df, top_selection) Arguments: language_df: Data frame with aggregated language information top_selection: Number of different languages to include within the plot Value: Returns a plot languages with the most number of students who speak it "],
["link-and-page-overview.html", "6 Link and Page Overview 6.1 Data Cleaning Pipeline 6.2 Visualization Reasoning and Caveats", " 6 Link and Page Overview 6.1 Data Cleaning Pipeline 6.2 Visualization Reasoning and Caveats Instructors often place external links within their courses. These links are are usually a supplementary reference such as an article or video. As a result, student engagement with these links are shown within the dashboard: Instructors may also be interested in engagement with other course pages that do not contain videos or problems. These pages may include things such as the course syllabus or articles. As a result, the following plot has been included within the dashboard: Overall, these two tables help instructors accomplish two tasks: Determine external links which have abnormal click rates Determine which pages which have abnormally high or low views and redesign pages appropriately "],
["link-and-page-dashboard-functions.html", "7 Link and Page Dashboard Functions 7.1 Wrangling Functions 7.2 Server Functions", " 7 Link and Page Dashboard Functions 7.1 Wrangling Functions 7.1.1 read_course_axis Import course_axis.csv files based on specified course folder name Description: Import course_axis.csv files based on specified course folder name Usage: read_course_axis(input_course) Arguments: input_course: Value: course_axis Examples: read_course_axis(input_couse = &quot;psyc1&quot;) 7.1.2 read_link_dirt Import external_link_dirt.csv files based on specified course folder name Description: Import external_link_dirt.csv files based on specified course folder name Usage: read_link_dirt(input_course) Arguments: input_course: Value: link_dirt Examples: read_link_dirt(input_couse = &quot;psyc1&quot;) 7.1.3 hash_username Anonyanonymize the username column as hash strings in the input_df Description: Anonyanonymize the username column as hash strings in the input_df Usage: hash_username(input_df) Arguments: input_df: A dataframe containing username column Value: secure_df Examples: hash_username(input_df = link_dat) 7.1.4 set_activity_level Set three levels for students total spending time on course based on tracklog link data Description: Set three levels for students total spending time on course based on tracklog link data Usage: set_activity_level(link_data) Arguments: link_data: dataframe containing the information of student click any links in the edx course Value: link_data Examples: set_activity_level(link_data = read_link_dirt) 7.1.5 get_module_of_link Get which module each external link locate based on link tracklog data and course axis data Description: Get which module each external link locate based on link tracklog data and course axis data Usage: get_module_of_link(link_data, course_axis) Arguments: link_data: dataframe containing the information of student click any links in the edx course course_axis: dataframe containing all elements in the edx course Value: link_data Examples: get_module_of_link(link_data = set_activity_level, course_axis = read_course_axis) 7.1.6 write_link_clean Export the tidy link dataframe Description: Export the tidy link dataframe Usage: write_link_clean(input_course, cleaned_data) Arguments: input_course: cleaned_data: tidy link dataframe Examples: write_link_clean(input_course = &quot;psyc1&quot;,cleaned_data = get_module_of_link) 7.1.7 read_page_dirt Import page_dirt.csv files from specified course folder name Description: Import page_dirt.csv files from specified course folder name Usage: read_page_dirt(input_course) Arguments: input_course: Value: page_dirt Examples: read_page_dirt(input_couse = &quot;psyc1&quot;) 7.1.8 prepare_tidy_page Prepare tidy page tracklog data for making page summary table Description: Prepare tidy page tracklog data for making page summary table Usage: prepare_tidy_page(page_data) Arguments: page_data: Value: log_data Examples: prepare_tidy_page(page_data = read_page_dirt) 7.1.9 prepare_page_name Get non-video and non-problem element name then create a chapter/module column for all these course elements Description: Get non-video and non-problem element name then create a chapter/module column for all these course elements Usage: prepare_page_name(course_axis) Arguments: course_axis: dataframe containing all course elements information Value: page_name Examples: prepare_page_name(course_axis = read_course_axis) 7.1.10 write_page_clean Export the tidy page dataframe Description: Export the tidy page dataframe Usage: write_page_clean(input_course, cleaned_data) Arguments: input_course: cleaned_data: tidy page dataframe Examples: write_page_clean(input_course = &quot;psyc1&quot;,cleaned_data = prepare_tidy_page) 7.1.11 wrangle_link_page Read in three csv files getting from rbq.py : course_axis.csv, external_link_dirt.csv and page_dirt.csv; perform wrangling; export three csv files for building link_page_dashabord: external_link.csv, page.csv and page_name.csv Description: Read in three csv files getting from rbq.py : course_axis.csv, external_link_dirt.csv and page_dirt.csv; perform wrangling; export three csv files for building link_page_dashabord: external_link.csv, page.csv and page_name.csv Usage: wrangle_link_page(input_course) Arguments: input_course: Examples: wrangle_link_page(input_cours = &quot;psyc1&quot;) 7.2 Server Functions 7.2.1 filter_chapter_linkpage Filter course item dataframe by the selected course module. Description: Filter course item dataframe by the selected course module. Usage: filter_chapter_linkpage(input_df, module = &quot;All&quot;) Arguments: input_df: The link dataframe or page dataframe. module: One of the modules in the course Value: A dataframe filtered by the selected course module. Examples: filter_chapter(tower_item, &quot;all&quot;) 7.2.2 get_pageview Count the pageview of each page.Here, we set a threshold for only counting pages have been viewed by more than certain amount of students. Description: Count the pageview of each page.Here, we set a threshold for only counting pages have been viewed by more than certain amount of students. Usage: get_pageview(filtered_log_df) Arguments: filtered_log_df: A page related tracklog dataframe after filtering. Value: page_student A page summary dataframe containing the pageview of each pages. Examples: get_pageview(filtered_log_df = log_dat) 7.2.3 get_page_name Get the name description of each page. Description: Get the name description of each page. Usage: get_page_name(page_name_df) Arguments: page_name_df: A dataframe we get after joining page dataframe and page name dataframe. Value: each_page Examples: get_page_name(page_name_df = page_name_mapping) 7.2.4 get_unique_page_name Remove duplicated name for each page. Description: Remove duplicated name for each page. Usage: get_unique_page_name(each_page_df) Arguments: each_page_df: Value: all_pages Examples: get_unique_page_name(each_page_df = each_page) 7.2.5 creat_page_table create a page summary table to show page(name,clickable hyperlink) and its page view sorted by pageview in descending order Description: create a page summary table to show page(name,clickable hyperlink) and its page view sorted by pageview in descending order Usage: creat_page_table(page_summary) Arguments: page_summary: Value: page_df Examples: creat_page_table(page_summary = reactive_page()) 7.2.6 get_click_per_link Compute how many times each external link have been clicked. Description: Compute how many times each external link have been clicked. Usage: get_click_per_link(link_df) Arguments: link_df: A link dataframe. Value: link_num A link dataframe with number of click information. Examples: get_click_per_link(link_df = link_dat) 7.2.7 creat_link_table Create a page summary table to show page(name,clickable hyperlink) and its page view sorted by pageview in descending order Description: Create a page summary table to show page(name,clickable hyperlink) and its page view sorted by pageview in descending order Usage: creat_link_table(link_summary) Arguments: page_summary: Value: page_df Examples: creat_page_table(page_summary = reactive_page()) "],
["discussion-forum-overview.html", "8 Discussion Forum Overview 8.1 Data Cleaning Pipeline 8.2 Visualization Reasoning and Caveats", " 8 Discussion Forum Overview 8.1 Data Cleaning Pipeline All of the forum data is available in BigQuery, but some of the relevant variables are in obscure files that are separate from the standard query tables. Below is a diagram of the pipeline for acquiring and processing the forum data: The python script rbq.py (Run BigQuery) calls three SQL scripts, which query from the BigQuery tables person_course, forum, and forum_events. rbq.py also pulls in prod_analytics.json and xbundle.xml. This results in five raw data files which are then stored on Azure: forum_posts.csv forum_views.csv forum_searches.csv prod_analytics.json xbundle.xml Each of these files passes through wrangle_forum.R, which results in five new files: wrangled_forum_posts.csv wrangled_forum_views.csv wrangled_forum_words.csv wrangled_forum_searches.csv wrangled_forum_elements.csv Each of these is then loaded into the edXviz dashboard. 8.1.1 Hierarchy of the Discussion Forums One of the primary goals of the forum view of the edXviz dashboard is to assist the user in viewing student engagement at different levels of aggregation within the discussion forum’s hiearchy. The hierarchy is shown in the diagram below: Within a given course, the highest level of the hierarchy is comprised of categories. These are often given titles such as “General Questions”, “Part 1”, or “Assignments”, although these are determined entirely by the instructor or course designer. Crucially, categories do not necessarily have a one-to-one correspondence with the modules of the course, and therefore their sequence may not have a temporal element. Some categories may have subcategories. If so, each of the discussion posts in that category will be associated with exactly one subcategory. There are two types of Initial posts: Discussion posts, and Question posts. These are determined by the user when they create the post; they must select a radio button before submitting. Initial posts, whether Discussion or Question, are also given titles, determined by the poster. After an Initial post has been created, users can create Response posts, each of which will be associated with exactly one Initial post. After a Response post has been created, users can create Comment posts, each of which will be associated with exactly one Response post. 8.1.2 Hierarchy Data Integrity Issues One of the main challenges of wrangling this data was that the variables and unique identifiers associated with each level of the hierarchy have different names, or are occasionally missing, in each of the relevant files. I’ve summarized these discrepancies in the table below. The reason I join with the prod_analytics.json file is that it is the only one that has all the category and subcategory names. The reason I join with the xbundle.xml file is that it is the only one that has the correct ordering of categories/subcategories, as defined by the instructor. 8.2 Visualization Reasoning and Caveats 8.2.1 Filter panel At the top of the forum view, like in all the views, there is a panel for filtering students: The filter panel allows the user to subset the students according to three variables: Activity level (defined by the total time spent on the course website) Gender Registration Status (verified or audit) There is one other dropdown menu that affects the filtering: Category. This was placed in the main plot for easier navigation, especially in conjunction with the Subcategory dropdown, which only appears when a category has been selected. The forum filter panel also displays two numbers: Number of authors: the number of filtered individuals who have posted at least once in the discussion forum. Number of viewers: the number of filtered individuals who have viewed the discussion forum at least once. Authors and viewers are not disjunct groups. That is, if you are an author then you are probably a viewer (more on why “probably” below), but if you are a viewer then you are not necessarily an author. Another important note is that when a category is selected in the main plot, this will update the numbers displayed in the filter panel. But when a subcategory is selected, it will not update the numbers. This is by design; the intention is that the numbers in the filter panel show the totals for all the bars that appear in the main plot at any given moment, even if those bars are not selected. One final feature of the filter panel is the Reset button, which allows the user to quickly go back to all students and all categories. The only thing that the Reset button does not change is the variable on the x-axis of the barchart. The assumption is that instructors would mainly be using the Reset button to remove filter settings, not to change the variable of interest. 8.2.2 Barchart The purpose of the main barchart is twofold. First, it is to enable comparisons of engagement across forum categories and subcategories. This tells the instructor which categories are the most active. Second, it is to identify categories or subcategories that may be worth examining in greater detail, using the wordcloud or the forum threads table. The main barchart displays either categories or subcategories on the y-axis, and one of three variables on the x-axis, depending on the user’s selections. The default variable that is shown on the x-axis is the number of posts: The categories and subcategories are ordered by the layout that the instructor or course designer defined when writing the course XML. There was a time when there was a radio button for reordering the bars by their rank on the numeric variable on the x-axis, but through useability testing, we determined that most courses have two few categories, or subcategories per category, for this to be a useful enough feature to justify adding more clutter to the interface. If the user selects the checkbox that says “Show post types”, then the barchart becomes a stacked barchart, with each color representing a different post type: This is an important feature because it helps the user distinguish between categories or subcategories where the students are engaging with each other (indicated by a healthy mix of initial posts, responses, and comments) and categories or subcategories where students are simply writing into a void (indicated by a high number of initial posts, but few responses or comments). The barchart can also show the number of unique authors who have participated in each category or subcategory: This is included partly to give information that is isomorphic to the information that is provided in the Eiffel Tower plot, and partly to help instructors distinguish between categories or subcategories where many students are participating, and categories or subcategories where there is lots of participation but few students are responsible for it. On this note, one idea for another variable option for the x-axis would be posts per student (who posted at least once in that category or subcategory). This would tell the instructor which categories or subcategories are especially conducive to multiple posts by a given student. This additional option would not be difficult to implement. Finally, the barchart can show the number of views in each category or subcategory. This option is included because many students are active readers of the discussion forums, but rarely write posts themselves. A view is defined as a pageview of an initial post. So, the view will only be recorded if the user has clicked on one of the initial posts whose titles are listed on the left-hand side of the edX discussion forum (circa June 2017). In BigQuery, this event is defined as forum_action = read in the forum_events table, where thread_id matches the mongoid of either a discussion post or question post in the forum_posts table. Currently, it is not possible to track views of specific responses or comments. There is another type of view event listed in BigQuery, which is deliberately ignored in the edX dashboard. These are events when the user views the titles of the initial posts in a given subcategory, but has not yet clicked on one. In BigQuery, this event is defined as forum_action = read_inline in the forum_events table. For future reference, is possible to identify the subcategory the student is browsing in because subject in the forum_events table matches commentable_id in the forum_posts table, and discussion_id in prod_analytics.json. 8.2.3 Wordcloud When the instructor goes to the discussion forum itself, they have no way of getting a high-level picture of the topics being discussed in their course. This is the goal of the wordcloud, which shows the most-used words at whichever level of aggregation the user has selected: For example, if all categories are selected, then the wordcloud shows the most-used words (written by the filtered students) in the whole course. If a category is selected, the wordcloud shows the most-used words for that category. Likewise, if a subcategory is selected, the wordcloud shows the most-used words for that subcategory. 8.2.4 Threads Table By default, the threads table shows the most-viewed initial posts for whatever level of aggregation the user has selected. The user can reorder by the number of responses or comments, if they like, and they can also search for specific users, subcategories, or words. This table is included so that the user can obtain details on demand, i.e. drill down even further than the selected subcategories in the barchart. This also allows for verification of the post type counts shown in the stacked barchart, as well as verification of the wordcloud. (However, the wordcloud shows words from responses and comments as well, which are not included in the threads table. This could be easily changed, if it is desired.) Finally, the threads table provides context for the words that show up in the wordcloud. 8.2.5 Searches Table The edX discussion forum has a search bar, which allows users to look up keywords of interest. This data is tracked, and could be useful to instructors, as it likely correlates with questions or interests that students have. The searches table ranks terms by the number of unique users who have searched for them. The searches table, like all the other elements of the forum view, is updated when the user changes the settings in the filter panel. This allows the instructor to figure out, for example, what verified students are searching for. 8.2.6 Interactivity and Navigation Aside from the filter panel, the user has four options for interacting with the forum view of the dashboard. The first is the x-axis variable. The second is the checkbox, “Show post types”, which only appears if the x-axis variable is “Posts”. When this checkbox is selected and all categories are selected, the full main view of the dashboard should look like this: The third option for interactivity is Category dropdown menu. When a user selects a category, the barchart will show one bar for each subcategory in the selected category. Also, a new dropdown menu will appear — the fourth option for interactivity — which allows the user to select a subcategory: When the user does select a subcategory, the transparency of the unselected bars will be diminished, like so: The titles and subtitles of the barplot, wordcloud, and threads table will also be updated to reflect the user’s selections.These small changes help to keep the user mentally situated at whichever level of the hierarchy they have chosen to view information. "],
["discussion-forum-dashboard-functions.html", "9 Discussion Forum Dashboard Functions 9.1 Wrangling Functions 9.2 Server Functions", " 9 Discussion Forum Dashboard Functions 9.1 Wrangling Functions 9.1.1 get_activity_levels 9.1.1.1 Main Documentation Convert sum_dt to activity_level. Description: Convert sum_dt to activity_level. Usage: get_activity_levels(forum) Arguments: forum: A forum dataframe. Value: The same dataframe with a new column for activity_level. Examples: get_activity_levels(forum) 9.1.2 get_discussion_vars_json 9.1.2.1 Main Documentation Get the variables associated with each forum element in the JSON file. (for use in &#39;prepare_json&#39;). Description: Get the variables associated with each forum element in the JSON file. (for use in &#39;prepare_json&#39;). Usage: get_discussion_vars_json(i, all_elements) Arguments: i: An iterator. all_elements: A nested list containing attributes for each course element. Value: A vector containing the &#39;commentable_id&#39;, &#39;display_name&#39;, &#39;discussion_category&#39;, and &#39;discussion_target&#39; of a course element. Examples: get_discussion_vars_json(i, all_elements) 9.1.3 get_discussion_vars_xml 9.1.3.1 Main Documentation Get the variables associated with each forum element in the XML file (for use in &#39;prepare_xml&#39;). Description: Get the variables associated with each forum element in the XML file (for use in &#39;prepare_xml&#39;). Usage: get_discussion_vars_xml(i, all_parameters) Arguments: i: An iterator. all_parameters: An XML tree containing all the parameters associated with each discussion node. Value: A vector containing the &#39;display_name&#39;, &#39;discussion_category&#39;, and &#39;discussion_target&#39; of a course element. Examples: get_discussion_vars_xml(i, all_parameters) 9.1.4 infer_post_subcategories 9.1.4.1 Main Documentation Infer the subcategories of each post, even if it&#39;s a response post or a comment. Description: Infer the subcategories of each post, even if it&#39;s a response post or a comment. Usage: infer_post_subcategories(forum) Arguments: forum: A forum dataframe. Value: The same dataframe with commentable_id filled in for everything. Examples: infer_post_subcategories(forum) 9.1.5 prepare_json 9.1.5.1 Main Documentation Prepare the JSON file for joining with the XML file. Description: Prepare the JSON file for joining with the XML file. Usage: prepare_json(json) Arguments: json: A JSON file containing information about the course elements. Value: A dataframe with four columns: &#39;commentable_id&#39;, &#39;display_name&#39;, &#39;discussion_category&#39;, and &#39;discussion_target&#39;. Examples: prepare_json(json) 9.1.6 prepare_posts 9.1.6.1 Main Documentation Prepare the forum posts. Description: Prepare the forum posts. Usage: prepare_posts(forum) Arguments: forum: A dataframe with one post per row. Value: The prepared forum posts data. Examples: prepare_posts(forum) 9.1.7 prepare_searches 9.1.7.1 Main Documentation Prepare the forum searches dataframe. Description: Prepare the forum searches dataframe. Usage: prepare_searches(forum) Arguments: forum: A dataframe with one search event per row. Value: The forum searches data with a new column for activity level. Examples: prepare_searches(forum) 9.1.8 prepare_views 9.1.8.1 Main Documentation Prepare the forum views dataframe. Description: Prepare the forum views dataframe. Usage: prepare_views(forum) Arguments: forum: A dataframe with one read event per row. Value: The prepared forum views data. Examples: prepare_views(forum) 9.1.9 prepare_words 9.1.9.1 Main Documentation Prepare the forum words. Description: Prepare the forum words. Usage: prepare_words(forum) Arguments: forum: A dataframe with one row per post. Value: The dataframe with each row containing a word, prepared for joining with the forum elements. Examples: prepare_words(forum) 9.1.10 prepare_xml 9.1.10.1 Main Documentation Prepare the XML file for joining with the JSON file. Description: Prepare the XML file for joining with the JSON file. Usage: prepare_xml(xml) Arguments: xml: An XML file containing information about the course elements. Value: A dataframe with three columns: &#39;display_name&#39;, &#39;discussion_category&#39;, and &#39;discussion_target&#39;. Examples: prepare_xml(xml) 9.1.11 wrangle_forum 9.1.11.1 Main Documentation Write the forum posts and forum words to csv. Description: Write the forum posts and forum words to csv. Usage: wrangle_forum(posts_input_path, views_input_path, searches_input_path, json_input_path, xml_input_path, posts_output_path, words_output_path, views_output_path, searches_output_path, elements_output_path) Arguments: posts_input_path: The path to the CSV file containing the forum posts data. views_input_path: The path to the CSV file containing the forum reads data. searches_input_path: The path to the CSV file containing the forum searches data. json_input_path: The path to the JSON file containing data on all course elements. xml_input_path: The path to the XML file containing data on the course structure. posts_output_path: The desired path to which to write the prepared forum posts dataframe. words_output_path: The desired path to which to write the prepared forum words dataframe. views_output_path: The desired path to which to write the prepared forum views dataframe. searches_output_path: The desired path to which to write the prepared forum searches dataframe. elements_output_path: The desired path to which to write the prepared forum elements dataframe. Value: None. Examples: wrangle_forum(csv_path, json_path, xml_path) 9.2 Server Functions 9.2.1 apply_forum_filters 9.2.1.1 Main Documentation Apply the selected filter settings to the forum data. Description: Apply the selected filter settings to the forum data. Usage: apply_forum_filters(input_df, forum_elements, activity_level = &quot;All&quot;, gender = &quot;All&quot;, registration_status = &quot;All&quot;, category = &quot;All&quot;) Arguments: input_df: The input dataframe. forum_elements: The forum elements dataframe. activity_level: One of &#39;under_30_min&#39;, &#39;30_min_to_5_hr&#39;, &#39;over_5_hr&#39;, or (default) &#39;All&#39;. gender: One of &#39;male&#39;, &#39;female&#39;, &#39;other&#39;, or (default) &#39;All&#39;. registration_status: One of &#39;audit&#39;, &#39;verified&#39;, or (default) &#39;All&#39;. category: One of the forum categories. Value: &#39;filtered_df&#39; A dataframe filtered by the selected settings. Examples: apply_forum_filters(forum_posts, forum_elements, &quot;All&quot;, &quot;All&quot;, &quot;All&quot;) 9.2.2 calculate_forum_searches 9.2.2.1 Main Documentation Calculates the number of unique users who searched for each search query, given the selected filters. Description: Calculates the number of unique users who searched for each search query, given the selected filters. Usage: calculate_forum_searches(forum_searches = wrangled_forum_searches, forum_elements, activity_level, gender, registration_status, category) Arguments: forum_searches: The wrangled forum searches dataframe. forum_elements: The forum elements dataframe. activity_level: The activity level of the students. gender: The gender of the students. registration_status: The registration status of the students. category: The forum category. Value: &#39;forum_searches&#39; The filtered forum searches dataframe. Examples: calculate_forum_searches(wrangled_forum_searches, &quot;under_30_min&quot;, &quot;female&quot;, &quot;verified&quot;, &quot;Part 3&quot;) 9.2.3 count_authors 9.2.3.1 Main Documentation Count the number of authors for each subcategory in an input forum. Description: Count the number of authors for each subcategory in an input forum. Usage: count_authors(input_forum, wrangled_forum_elements) Arguments: input_forum: The input dataframe containing a row for each post in the forum. wrangled_forum_elements: A dataframe containing information about each of the forum subcategories. Value: &#39;author_counts&#39; A dataframe containing the unique author counts for each subcategory in the forum. Examples: count_authors(wrangled_forum_posts) 9.2.4 count_posts 9.2.4.1 Main Documentation Count the number of posts for each subcategory in an input forum. Description: Count the number of posts for each subcategory in an input forum. Usage: count_posts(input_forum, wrangled_forum_elements) Arguments: input_forum: The input dataframe containing a row for each post in the forum. wrangled_forum_elements: A dataframe containing information about each of the forum subcategories. Value: &#39;post_counts&#39; A dataframe containing the post counts for each subcategory in the forum. Examples: count_posts(wrangled_forum_posts) 9.2.5 count_views 9.2.5.1 Main Documentation Count the number of view events for each subcategory in an input forum. Description: Count the number of view events for each subcategory in an input forum. Usage: count_views(input_forum, wrangled_forum_elements) Arguments: input_forum: The input dataframe containing a row for each read event in the forum. wrangled_forum_elements: A dataframe containing information about each of the forum subcategories. Value: &#39;view_counts&#39; A dataframe containing the read counts for each subcategory in the forum. Examples: count_views(wrangled_forum_views) 9.2.6 filter_forum_elements 9.2.6.1 Main Documentation Filter the forum elements by the selected filter variables. Description: Filter the forum elements by the selected filter variables. Usage: filter_forum_elements(forum_elements, category) Arguments: forum_elements: The forum elements dataframe that was passed in from the wrangling script. category: The forum category that the user has selected. Details: The forum elements dataframe only needs to be filtered by category, since it doesn&#39;t include any variables related to students. Value: &#39;filtered_forum_elements&#39; The same dataframe, filtered by category if appropriate. Examples: filter_forum_elements(wrangled_forum_elements, &quot;Part 1&quot;) 9.2.7 filter_wordcloud_data 9.2.7.1 Main Documentation Filter the wordcloud data by the selected filters. Description: Filter the wordcloud data by the selected filters. Usage: filter_wordcloud_data(forum_words, forum_elements, activity_level, gender, registration_status, category) Arguments: forum_words: The forum words dataframe passed in from the wrangling script. forum_elements: The forum elements dataframe. activity_level: The activity level of the students. gender: The gender of the students. registration_status: The registration status of the students. category: The forum category. Value: &#39;filtered_wordcloud_data&#39; The filtered forum words dataframe. Examples: filter_wordcloud_data(wrangled_forum_words, forum_elements, &quot;30_min_to_5_hr&quot;, &quot;female&quot;, &quot;All&quot;, &quot;General&quot;) 9.2.8 gather_post_types 9.2.8.1 Main Documentation Gather the post types into a single column for easy plotting. Description: Gather the post types into a single column for easy plotting. Usage: gather_post_types(forum_data, grouping_var) Arguments: forum_data: The forum data for the main barplot. grouping_var: grouping_var One of &#39;discussion_category&#39; or &#39;display_name&#39;, depending on whether a category has been selected. Value: &#39;gathered&#39; A dataframe with the post types gathered into a single column. Examples: gather_post_types(forum_data, grouping_var = &quot;discussion_category&quot;) 9.2.9 get_author_count 9.2.9.1 Main Documentation Get the number of authors for which the selected filter settings apply. Description: Get the number of authors for which the selected filter settings apply. Usage: get_author_count(forum_posts, forum_elements, activity_level, gender, registration_status, category) Arguments: forum_posts: The forum posts dataframe that was passed in from the wrangling script. forum_elements: The forum elements dataframe. activity_level: The activity level of the students. gender: The gender of the students. registration_status: The registration status of the students. category: The forum category. Value: &#39;author_count&#39; A string showing the number of authors. Examples: get_author_count(wrangled_forum_posts, forum_elements, &quot;All&quot;, &quot;male&quot;, &quot;verified&quot;, &quot;All&quot;) 9.2.10 get_forum_threads 9.2.10.1 Main Documentation Get the forum threads for the authors who match the filter settings. Description: Get the forum threads for the authors who match the filter settings. Usage: get_forum_threads(forum_posts, forum_elements, activity_level, gender, registration_status, category, selected_subcategory) Arguments: forum_posts: The forum posts dataframe that was passed in from the wrangling script. forum_elements: The forum elements dataframe. activity_level: The activity level of the students. gender: The gender of the students. registration_status: The registration status of the students. category: The selected forum category. selected_subcategory: The selected forum subcategory. Value: &#39;forum_threads&#39; The forum threads that were authored by students for which the filter settings apply. Examples: get_forum_threads(forum_posts = wrangled_forum_posts, forum_elements, &quot;over_5_hr&quot;, &quot;female&quot;, &quot;audit&quot;, &quot;All&quot;, &quot;All&quot;) 9.2.11 get_label_lengths 9.2.11.1 Main Documentation Get the lengths of the labels on the main barplot (either the categories or the subcategories). Description: Get the lengths of the labels on the main barplot (either the categories or the subcategories). Usage: get_label_lengths(forum_data, category) Arguments: forum_data: The forum data for the main barplot. category: The selected category. Value: &#39;label_lengths&#39; A list with the lengths (in characters) of each label on the main plot. Examples: get_label_lengths(forum_data, &quot;Technical Questions&quot;) 9.2.12 get_post_types 9.2.12.1 Main Documentation Get the post types. Description: Get the post types. Usage: get_post_types(forum) Arguments: forum: A forum dataframe. Value: The same dataframe with a new column for post_type. Examples: get_post_types(forum) 9.2.13 get_subcategory_options 9.2.13.1 Main Documentation Get the options for the subcategory options, given the selected category. Description: Get the options for the subcategory options, given the selected category. Usage: get_subcategory_options(category, filtered_forum_elements) Arguments: category: The selected category. filtered_forum_elements: The forum elements dataframe, filtered by the selected category. Value: &#39;subcategory_options&#39; A list of options for the user to select from. Examples: get_subcategory_options(&quot;Part 1&quot;, filtered_forum_elements) 9.2.14 get_target_word_counts 9.2.14.1 Main Documentation Get the top words for each subcategory. Description: Get the top words for each subcategory. Usage: get_target_word_counts(input_forum) Arguments: input_forum: The input dataframe containing a row for each word in the forum. Value: &#39;word_counts&#39; A dataframe containing the counts for each word in each subcategory. Examples: get_target_word_counts(wrangled_forum_words) 9.2.15 get_wordcloud_data 9.2.15.1 Main Documentation Get the counts of each word in the selected subcategories. Description: Get the counts of each word in the selected subcategories. Usage: get_wordcloud_data(filtered_wordcloud_data, filtered_forum_elements, category, selected_subcategory) Arguments: filtered_wordcloud_data: The filtered forum words dataframe. filtered_forum_elements: The filtered forum elements dataframe. category: The selected category. selected_subcategory: The selected subcategory. Value: &#39;wordcloud_data&#39; A dataframe with the counts of each word in the selected subcategory(ies). Examples: get_wordcloud_data(filtered_wordcloud_data, filtered_forum_elements, &quot;Part 1&quot;, &quot;Part 1 Lecture 1 Discussion&quot;) 9.2.16 make_forum_barplot 9.2.16.1 Main Documentation Make the main barplot for displaying the forum data. Description: Make the main barplot for displaying the forum data. Usage: make_forum_barplot(forum_data, xvar_string, plot_variable, fill_value, axis_limit, category, ylabel, breakdown) Arguments: forum_data: The forum data for the main barplot. xvar_string: A string that matches the function to call for the x value of aes_string(). plot_variable: One of (default) &#39;posts&#39;, &#39;authors&#39;, or &#39;views&#39;. fill_value: A hex value representing the color for the bar fill. axis_limit: The maximum axis limit for the horizontal axis in the main barplot. category: The selected category. ylabel: The label of the y-axis in the main barplot. breakdown: One of &#39;TRUE&#39; or &#39;FALSE&#39;; determines whether the post types breakdown is shown. Value: &#39;forum_barplot&#39; A ggplot2 object to be rendered as the main forum barplot. Examples: make_forum_barplot(forum_data, xvar_string = &quot;fct_reorder(discussion_category, course_order, .desc = TRUE)&quot;, plot_variable = &quot;authors&quot;, fill_value = &quot;red&quot;, axis_limit = 100, category = &quot;All&quot;, ylabel = &quot;Category&quot;, breakdown = FALSE) 9.2.17 make_forum_breakdown_barplot 9.2.17.1 Main Documentation Make the main forum barplot with the post types breakdown. Description: Make the main forum barplot with the post types breakdown. Usage: make_forum_breakdown_barplot(gathered, xvar_string, grouping_var, axis_limit, xlabel) Arguments: xvar_string: A string that matches the function to call for the x value of aes_string(). grouping_var: grouping_var One of &#39;discussion_category&#39; or &#39;display_name&#39;, depending on whether a category has been selected. axis_limit: The maximum axis limit for the horizontal axis in the main barplot. xlabel: The label of the x-axis in the main barplot. forum_data: The forum data for the main barplot. Value: &#39;forum_breakdown_barplot&#39; A ggplot2 object to be rendered as the main forum barplot. Examples: make_forum_breakdown_barplot(forum_data = forum_data, xvar_string = &quot;fct_reorder(discussion_category, course_order, .desc = TRUE)&quot;, axis_limit = 100, grouping_var = &quot;discussion_category&quot;, xlabel = &quot;Category&quot;) 9.2.18 make_wordcloud 9.2.18.1 Main Documentation Make the wordcloud. Description: Make the wordcloud. Usage: make_wordcloud(wordcloud_data, max_words = 20, scale = c(3.5, 1)) Arguments: wordcloud_data: A dataframe showing the counts of the top words in the selected subcategory. max_words: The maximum number of words to show in the wordcloud. Default is 20. scale: A list giving the range of sizes to for the display of words in the wordcloud. Default is c(3.5,1). Value: A wordcloud object. Examples: make_wordcloud(wordcloud_data, max_words = 30, scale = c(4,1.5)) 9.2.19 set_axis_limit 9.2.19.1 Main Documentation Warning in parse_Rd(&quot;../../r-package/man/set_axis_limit.Rd&quot;, encoding = &quot;unknown&quot;, : ../../r-package/man/set_axis_limit.Rd:21: unexpected section header &#39;\\value&#39; Warning in parse_Rd(&quot;../../r-package/man/set_axis_limit.Rd&quot;, encoding = &quot;unknown&quot;, : ../../r-package/man/set_axis_limit.Rd:24: unexpected section header &#39;\\description&#39; Warning in parse_Rd(&quot;../../r-package/man/set_axis_limit.Rd&quot;, encoding = &quot;unknown&quot;, : ../../r-package/man/set_axis_limit.Rd:27: unexpected section header &#39;\\details&#39; Warning in parse_Rd(&quot;../../r-package/man/set_axis_limit.Rd&quot;, encoding = &quot;unknown&quot;, : ../../r-package/man/set_axis_limit.Rd:33: unexpected section header &#39;\\examples&#39; Warning in parse_Rd(&quot;../../r-package/man/set_axis_limit.Rd&quot;, encoding = &quot;unknown&quot;, : ../../r-package/man/set_axis_limit.Rd:36: unexpected END_OF_INPUT &#39; &#39; Set the horizontal axis limit of the main barplot. Usage: set_axis_limit(forum_data, plot_variable, label_lengths, min_axis_length = 0.1, percent_addition_per_char = 0.023) Arguments: forum_data: The forum data for the main barplot. plot_variable: One of (default) &#39;posts&#39;, &#39;authors&#39;, or &#39;views&#39;. label_lengths: A list containing the lengths (in characters) of each label on the barplot. min_axis_length: The axis length to set if all the values are set to zero (i.e. all students have been filtered out). Default is 0.1 so that the axis is minimally affected when values are small. percent_addition_per_char: The percentage by which to expand the axis per character in the label of the longest bar. Default is 0.023, i.e. 2.3 &#39;axis_limit&#39; The maximum axis limit for the horizontal axis in the main barplot. Set the horizontal axis limit of the main barplot. Usually, the variance in bar lengths is greater than the variance in label lengths. If this is not the case, it is possible that the axis limit will need to be expanded further. For example, the second-longest bar may have a label that is twice as long as the label of the longest bar. In the future, it will be desirable to account for these cases. set_axis_limit(forum_data, &quot;views&quot;, c(15,12,14,7)) 9.2.20 set_breakdown 9.2.20.1 Main Documentation Determines whether the plot types breakdown will be shown. Description: Determines whether the plot types breakdown will be shown. Usage: set_breakdown(plot_variable, breakdown) Arguments: plot_variable: One of (default) &#39;posts&#39;, &#39;authors&#39;, or &#39;views&#39;. breakdown: One of &#39;TRUE&#39; or (default) &#39;FALSE&#39;. Details: This option only comes into play if the plot variable is &#39;posts&#39;. Value: &#39;TRUE&#39; or &#39;FALSE&#39; Examples: set_breakdown(plot_variable = &quot;posts&quot;, breakdown = FALSE) 9.2.21 set_forum_plot_title 9.2.21.1 Main Documentation Set the title of the main barplot, according to the relevant variable and category. Description: Set the title of the main barplot, according to the relevant variable and category. Usage: set_forum_plot_title(plot_variable, category) Arguments: plot_variable: One of (default) &#39;posts&#39;, &#39;authors&#39;, or &#39;views&#39;. Value: &#39;forum_plot_title&#39; A string for the plot title. Examples: set_forum_plot_title(&quot;views&quot;, &quot;Part 1&quot;) 9.2.22 set_forum_plot_ylabel 9.2.22.1 Main Documentation Set the label of the y-axis in the main barplot. Description: Set the label of the y-axis in the main barplot. Usage: set_forum_plot_ylabel(plot_variable) Arguments: plot_variable: One of (default) &#39;posts&#39;, &#39;authors&#39;, or &#39;views&#39;. Value: &#39;forum_plot_ylabe&#39; The label of the y-axis in the main barplot. Examples: set_forum_plot_ylabel(&quot;authors&quot;) 9.2.23 set_forum_threads_title 9.2.23.1 Main Documentation Set the title of the forum threads table. Description: Set the title of the forum threads table. Usage: set_forum_threads_title(category, selected_subcategory) Arguments: category: The selected category. selected_subcategory: The selected subcategory. Value: &#39;forum_threads_title&#39; A string for the title of the forum threads table. Examples: set_forum_threads_title(&quot;Part 3&quot;, &quot;All&quot;) 9.2.24 set_wordcloud_title 9.2.24.1 Main Documentation Set the title of the wordcloud. Description: Set the title of the wordcloud. Usage: set_wordcloud_title(category, selected_subcategory) Arguments: category: The selected category. selected_subcategory: The selected subcategory. Value: &#39;wordcloud_title&#39; A string for the wordcloud title. Examples: set_wordcloud_title(&quot;Part 3&quot;, &quot;All&quot;) 9.2.25 specify_forum_data_selection 9.2.25.1 Main Documentation Specify which subcategory has been selected. Description: Specify which subcategory has been selected. Usage: specify_forum_data_selection(updated_forum_data, category, selected_subcategory) Arguments: updated_forum_data: The dataframe containing the counts for each (sub)category. category: The selected category. selected_subcategory: The selected subcategory. Value: &#39;forum_w_selection&#39; The same dataframe with a new column, &#39;selected&#39;. Examples: specify_forum_data_selection(updated_forum_data, &quot;Part 1&quot;, &quot;Part 1 Video Discussion&quot;) 9.2.26 update_forum_data 9.2.26.1 Main Documentation Update the post, view, and author counts for the selected filters. Description: Update the post, view, and author counts for the selected filters. Usage: update_forum_data(forum_posts, forum_views, forum_elements, activity_level, gender, registration_status, category) Arguments: forum_posts: The forum posts dataframe passed in from the wrangling script. forum_views: The forum views dataframe passed in from the wrangling script. forum_elements: The forum elements dataframe passed in from the wrangling script. activity_level: The activity level of the students. gender: The gender of the students. registration_status: The registration status of the students. category: The forum category. Value: &#39;filtered_forum_data&#39; A dataframe with one row per subcategory (or category), and counts for each variable. Examples: update_forum_data(wrangled_forum_posts, wrangled_forum_views, filtered_forum_elements(), &quot;over_5_hr&quot;, &quot;other&quot;, &quot;audit&quot;, &quot;All&quot;) "],
["problem-overview.html", "10 Problem Overview 10.1 Data Cleaning Pipeline 10.2 The Structure of Problems and Assessments 10.3 Visualization Reasoning and Caveats", " 10 Problem Overview 10.1 Data Cleaning Pipeline There are two sources that problems draws from, the xbundle.xml found on Google Cloud Storage and Google BigQuery. Two SQL scripts are used to generate the data for the problems dashboard. The first, focused on multiple choice problems, retrieves data the problem_analysis, course_problem and and person_course tables. The second, focused on Open Response Assessments (ORAs), retrieves submission data from the event logs. Xbundle is used to look up questions and response strings from their IDs. The useful data in the Xbundle is extracted into JSON files by xml_extraction.py. The assessment data involves some regular expressions and is too slow to calculate oat run-time, so it is further processed by wrangle_assessments.R. Pipeline 10.2 The Structure of Problems and Assessments Currently, the problem dashboard only supports two types of problems: choicegroup and checkboxgroup. Both of these problems are multiple choice but checkboxgroup has several correct answers that must all be selected for full credit. Open Response Assessments can be evaluated by self, peer, or TA/instructor and can have an arbitrary number of items in it’s rubric. As an example, a programming assessment my assess the student on passing edge cases and code style. Assessments with only one item their rubric and multiple choice problems that have only correct responses are filtered out of the dashboard. Typically, these signal a survey question or ungraded self-reflection response. 10.3 Visualization Reasoning and Caveats 10.3.1 Module Overview The goal of the module overview is to provide the instructor with data on the difficulty curve of the entire course. All questions in each module are scored out of 100 and averaged. Note that the relative weights of the problems are not included. The modules appear in the same order as in the XML. The XML also dictates the name of the modules. Sometimes malformed XML can lead to sub-optimal module names. 10.3.2 Hardest Problems The three hardest problems intend to show the hardest problems (ordered hardest to least hard) and the response of each student. The aim of this plot is show not only show which problems students are struggling on, but also why they might be struggling. This plot works especially well with the module filter, since it allows the instructor to drill-down to the toughest problems for each module. 10.3.3 Assessments The assessments plot is a new feature to the EdX dashboard. It allows the instructor to see not only how students did on ORAs but also how they did in different subcategories. Note that unlike the multiple choice questions, 100% grades are allowed for assessments. "],
["problem-dashboard-functions.html", "11 Problem Dashboard Functions 11.1 Assessment Functions 11.2 Problems Functions", " 11 Problem Dashboard Functions 11.1 Assessment Functions 11.1.1 extract_assessment_json 11.1.1.1 Main Documentation Convert a JSON object into a tidyJSON dataframe Description: Convert a JSON object into a tidyJSON dataframe Usage: extract_assessment_json(assessment_json) Arguments: assessment_json: An JSON file generated through `xml_extraction &lt;course&gt; -assessments` Value: A flattened dataframe with the columns `url_name`, `title`, `label`, `name` 11.1.2 extract_assessment_csv 11.1.2.1 Main Documentation Convert a CSV respresenting an open_assessment.sql query into a usable format Description: Extracts the nececessary information from event JSON and discards it. Points possible should always be the same for each assessment. Usage: extract_assessment_csv(assessment_tbl) Arguments: assessment_tbl: Value: An extracted table 11.1.3 join_extracted_assessment_data 11.1.3.1 Main Documentation Join the results of extract_assessment_csv and extract_assessment_json Description: This function joins the BigQuery and XML data. This is needed to populate the BigQuery data with the title and label fields. If the ID of the assessment does not occur in the XML, it is removed before preceding. Usage: join_extracted_assessment_data(extracted_csv, extracted_json) Arguments: extracted_csv: the result of extract_assessment_csv extracted_json: the result of extract_assessment_csv Value: A joined dataframe of the two incoming dataframes 11.1.4 summarise_joined_assessment_data 11.1.4.1 Main Documentation Summarise assessment data for plotting Description: This function checks that the number of points possible does not vary within title-label groups. Usage: summarise_joined_assessment_data(joint_assessment, trunc_length = 20) Arguments: joint_assessment: The result of join_extracted_assessment_data trunc_length: The length of that the label should be truncated to. Do set to less than 4 Value: A summarised dataframe of the average scores in each area. 11.1.5 plot_assessment 11.1.5.1 Main Documentation Plot the summary assessment data Description: Plot the summary assessment data Usage: plot_assessment(summary_assessment) Arguments: summary_assessment: the resulting dataframe from `summary_assessment` Value: A faceted bar plot 11.2 Problems Functions 11.2.1 clean_multiple_choice 11.2.1.1 Main Documentation Clean a demographic multiple choice CSV Description: This function cleans a CSV retrieved from the `demographic_multiple_choice` SQL script. It transforms the `sum_dt` column into activity_level. It also removes any non-multiple choice problems. Usage: clean_multiple_choice(raw_csv) Arguments: raw_csv:: A dataframe from the read_csv Value: A dataframe with the same dimensions as the CSV 11.2.2 create_question_lookup_from_json 11.2.2.1 Main Documentation Parse a JSON object and return it as a flat dataframe. Description: This function is required to convert the JSON derived from the xbundle XML into a format that other dataframes can interact with. Usage: create_question_lookup_from_json(name_lookup) Arguments: name_lookup: A JSON object contain keys for `id`, `problem`, `chapter_name`, `chapter_name`, `choices`, `correct_id` and `correct` Value: A flat dataframe with the above columns 11.2.3 filter_valid_questions 11.2.3.1 Main Documentation Filter out invalid multiple choice problems Description: Removes problems that were marked as 100 problems where every answer is correct). Also checks from the dataframe derived from xbundle to ensure that the problem exists in the course. Usage: filter_valid_questions(problems_tbl, lookup_table) Arguments: problems_tbl: The result of `read_multiple_choice_csv` lookup_table: The result of `create_question_lookup_from_json` Value: The filtered problems_tbl 11.2.4 get_mean_scores 11.2.4.1 Main Documentation Get mean scores. Description: This function is not affected by filters. If you need a function that is, use `get_mean_scores_filterable`. Removes scores that do not appear in the xbundle XML or have a 100 questions masquerading as multiple choice problems. Usage: get_mean_scores(problems_tbl, lookup_table) Arguments: problems_tbl: The result of `clean_multiple_choice` lookup_table: The result of `create_question_lookup_from_json` Value: A dataframe with each problem, the number of users that attempted the problem and the percent score 11.2.5 tally_correct_answers 11.2.5.1 Main Documentation Count the number of correct answers for each question. Description: Count the number of correct answers for each question. Usage: tally_correct_answers(joined_scores) Arguments: joined_scores: `problems_tbl` and `lookup_table` joined by `id` and `item_response` Value: A summarised dataframe of correct counts 11.2.6 calculate_percent_correct_tbl 11.2.6.1 Main Documentation Calculate the percent of correct answers Description: Each row represents a problem. Usage: calculate_percent_correct_tbl(joined_scores, number_correct) Arguments: joined_scores: `problems_tbl` and `lookup_table` joined by `id` and `item_response` number_correct: the result of `tally_correct_answer` Value: A dataframe where each row is a row and the columns show the percentage and absolute number of students that got the problem correct. 11.2.7 get_mean_scores_filterable 11.2.7.1 Main Documentation A filterable version of get_mean_scores Description: A filterable version of get_mean_scores Usage: get_mean_scores_filterable(filtered_problems_tbl) Arguments: filtered_problems_tbl: The result of `read_multiple_choice_csv` filtered by demographics and chapter name_lookup: A JSON object contain keys for `id`, `problem`, `chapter_name`, `chapter_name`, `choices`, `correct_id` and `correct` Value: A dataframe where each row is a row and the columns show the percentage and absolute number of students that got the question correct. 11.2.8 join_summary_lookup 11.2.8.1 Main Documentation Join the summary and lookup tables Description: Join the summary and lookup tables Usage: join_summary_lookup(summarised_scores, lookup_table) Arguments: summarised_scores: the result of `get_mean_scores_filterable` lookup_table: The result of `create_question_lookup_from_json` Value: The inner join of the two dataframes 11.2.9 summarise_scores_by_chapter 11.2.9.1 Main Documentation Summarise scores by chapter Description: Calculates the average score on problems for each of the chapters based. Usage: summarise_scores_by_chapter(summarised_scores, lookup_table) Arguments: summarised_scores: the result of `get_mean_scores_filterable` lookup_table: The result of `create_question_lookup_from_json` Value: A dataframe where each row is a chapter that contains the average score on that chapter 11.2.10 prepare_filterable_problems 11.2.10.1 Main Documentation Produce a dataframe clean dataframe of all questions Description: Returns the question name and it&#39;s rounded percentage (out of 100). This function is used to prepare the data table shown at the bottom of the problem dashboard. Usage: prepare_filterable_problems(summarised_scores, lookup_table) Arguments: summarised_scores: the result of `get_mean_scores_filterable` lookup_table: The result of `create_question_lookup_from_json` Value: A dataframe with the question and percent correct. 11.2.11 get_extreme_summarised_scores 11.2.11.1 Main Documentation Select the easiest (or hardest) problems Description: Set the index negative to receive the hardest problems. Usage: get_extreme_summarised_scores(summarised_scores, index) Arguments: summarised_scores: the result of `get_mean_scores_filterable` index: the number of questions you wish to view Value: The summarised scores dataframe with the with the number of rows equal to the absolute value of the index. 11.2.12 join_problems_to_lookup 11.2.12.1 Main Documentation Left join extracted problems and lookup table Description: Left join extracted problems and lookup table Usage: join_problems_to_lookup(extracted_problems, lookup_table) Arguments: extracted_problems: the result of `clean_multiple_choice` lookup_table: The result of `create_question_lookup_from_json` Value: The left joined dataframe by id and choice_id, filtering out blank problems 11.2.13 join_users_problems 11.2.13.1 Main Documentation The left join of joined problems and summarised scores Description: The left join of joined problems and summarised scores Usage: join_users_problems(joined_problems, summarised_scores) Arguments: joined_problems: `problems_tbl` and `lookup_table` joined by `id` and `item_response` summarised_scores: the result of `get_mean_scores_filterable` Value: A left joined dataframe of joined problems and summarised scores 11.2.14 filter_counts 11.2.14.1 Main Documentation Count the number of filtered users for each problem Description: Count the number of filtered users for each problem Usage: filter_counts(joined_user_problems) Arguments: joined_user_problems: The result of `join_users_problems` Value: A dataframe with the count of unique users for each question 11.2.15 filter_extreme_problem_choices 11.2.15.1 Main Documentation Retrieve the question and choice information from the extreme problems Description: Retrieve the question and choice information from the extreme problems Usage: filter_extreme_problem_choices(lookup_table, extreme_problems, filtered_counts) Arguments: lookup_table: The result of `create_question_lookup_from_json` extreme_problems: The result of `get_extreme_summarised_score` filtered_counts: The result of `filter_counts` Value: A dataframe with lookup information attached 11.2.16 aggregate_extracted_problems 11.2.16.1 Main Documentation Perform the last wrangling before plotting extreme problems Description: Calculates the percent of students selected each option and determines if that option is correct. Usage: aggregate_extracted_problems(joined_user_problems, extreme_problems, question_choices) Arguments: joined_user_problems: The result of `join_users_problems` extreme_problems: The result of `get_extreme_summarised_score` question_choices: The result of `filter_extreme_problem_choices` Value: A dataframe with `problem,` `choice` and percent `correct` 11.2.17 aggregate_melted_problems 11.2.17.1 Main Documentation Aggregate questions before plotting Description: Aggregate questions before plotting Usage: aggregate_melted_problems(lookup_table, joined_user_problems, extreme_problems) Arguments: lookup_table: The result of `create_question_lookup_from_json` joined_user_problems: The result of `join_users_problems` extreme_problems: The result of `get_extreme_summarised_score` Value: A dataframe ready to be plotted by `plot_aggregated_problems` 11.2.18 plot_aggregated_problems 11.2.18.1 Main Documentation Plot aggregated problems Description: This funciton is used to plot the top or bottom questions. Usage: plot_aggregated_problems(agg_melted_problems) Arguments: agg_melted_problems: A dataframe with the problem and choice names as well as the number of students who chose each option. Value: A facetted ggplot bar chart 11.2.19 plot_problem_chapter_summaries 11.2.19.1 Main Documentation Overview plot (Chapter by Course) Description: Overview plot (Chapter by Course) Usage: plot_problem_chapter_summaries(chapter_summary_tbl) Arguments: chapter_summary_tbl: The aggregated data on a per chapter basis Value: A ggplot bar chart "],
["video-overview.html", "12 Video Overview 12.1 Data Cleaning Pipeline 12.2 Visualization Reasoning and Caveats:", " 12 Video Overview 12.1 Data Cleaning Pipeline The figure above shows the data cleaning pipeline for video data. Raw track log and video data is initially stored in Google BigQuery. It is downloaded and cleaned programatically through the populate_courses.py script. Next, the cleaned wrangled_video_heat.csv file is used to generate the video visualizations. 12.2 Visualization Reasoning and Caveats: In this section, we show visualizations included within our video dashboard. Additionally, the reasoning that went into their design as well as the caveats that go along with those decisions are provided. The main purpose of the plot above is to gain the trust of the instructor. Intuitively, instructors will already know that videos that occur later in the course are going to have less students because students are more likely drop the course. This allows instructors to trust what is put in front of them by seeing something that is intuitively correct. Additionally, this plot is a good introductory to the next plot. Initially, during usability testing, when showing the heat map plot below without showing the length of video plot above, instructors felt overwhelmed and had trouble interpreting the visualization. The heat map plot above shows which parts of the video are being viewed the most. The “watch rate” of each segment is calculated by the following equation: \\[\\text{Watch Rate} = (\\frac{\\text{Number of times a segment has been watched}}{\\text{Number of unique students who have started the video}})\\] In the above calculation of the watch rate, the “number of times a segment has been watched” is the raw count regardless of uniqueness of the user. This means that is a new user watches a video segment twice, the “number of times a segment has been watched” will increase by two The plot above was created as a request from usability testing. This shows the average maximum time that a users reach in a video. However, the diagram is slightly misleading. We are simply taking the maximum time that users reach in a video. We are not accounting for the fact that users max have skipped ahead in video time to achieved their maximum time in the video. This problem can be fixed relatively easily in future iterations. The plot above shows instructors which segments have abnormally high and low watch rates. It works by creating a linear model used to predict the watch rate of a given segment. The linear model is based on the video’s occurrence in the course as well as the segment’s position within the video. Once the predicted value has been calculated, segments with the highest and lowest residuals are highlighted. The table above shows much of the information already displayed in the visualizations above. During usability testing, it was discovered that users often want to see the actual numbers as well as the visualizations. "],
["video-dashboard-functions.html", "13 Video Dashboard Functions 13.1 Wrangling Functions 13.2 Server Functions", " 13 Video Dashboard Functions 13.1 Wrangling Functions 13.1.1 wrangle_video 13.1.1.1 Main Documentation Generates cleaned video data as a csv within a specified course directory Description: This function will automatically read files named &#39;generalized_video_heat.csv&#39; and &#39;generalized_video_axis.csv&#39; from the specified course directory and output a csv named &#39;wrangled_video_heat.csv&#39; in the same directory Usage: wrangle_video(input_course, testing = FALSE) Arguments: input_course: String of short name of course directory Value: No value returned Examples: wrangle_video(input_course = &#39;psyc1&#39;) 13.1.1.2 Additional Notes: In order for this function to execute properly, there must be two files in the course directory named “generalized_video_heat.csv” and “generalized_video_axis.csv”. These files are obtained from Google BigQuery. Typically, these files are automatically obtained through the “populate_courses.py” script within the “exec” directory. input_course corresponds to the “short name” within the “.config.json” file The following are descriptions of the columns within the output csv file: video_id: Video ID hash string video_name: Name of the video username: Username of the learner min_into_video: Minute into video of the segment that the learner has watched count: Number of times the learner has watched the segment mode: Whether or not the learner is auditing or a verified student certified: Whether or not the student has been certified gender: Gender of the learner activity_level: Length of time that the student has spent on the course max_stop_position: The mode time at which video_stop events occur. The mode is used instead of the maximum because some videos have video_stop events that occur at incorrect times such as 3 days. course_order: Order in which the video appears in the course index_chapter: Index of the chapter in which the video appears in chapter: Name of the chapter Each video segment is 20 seconds in length. This can be adjusted by changing the global constant SEGMENT_SIZE in the video_wrangling.R file. In order for a segment to be counted as being “viewed”, the user would have to watch the segment for at least 1 second before carrying out another event such as video_pause, video_seek, page_close etc. This threshold of 1 second can be adjusted via the global constant MIN_DURATION in the video_wrangling.R file. The largest length of a video is set to be 1 hour. Any segments passed 1 hour will simply be ignored/truncated. This can be adjusted by changing the global constant MAX_DURATION in the video_wrangling.R file. 13.1.2 obtain_raw_video_data 13.1.2.1 Main Documentation Reads raw uncleaned .csv into a dataframe Description: Reads the raw generalized_video_heat.csv obtained through rbq.py into a dataframe. Usage: obtain_raw_video_data(input_course, testing = FALSE) Arguments: input_course: Name of course directory (ex. psyc1, spd1, marketing, etc) testing: For developer use only. Boolean used to indicate to use testing data. Value: &#39;data&#39;: Dataframe containing raw student track log information Examples: obtain_raw_video_data(input_course = &#39;psyc1&#39;) 13.1.3 obtain_video_axis_data 13.1.3.1 Main Documentation Reads video_axis.csv file Description: Reads the video_axis csv obtained through rbq.py into a dataframe. For documentation on how to use rbq.py, please see www.temporaryreferencelink.com Usage: obtain_video_axis_data(input_course, testing = FALSE) Arguments: input_course: Name of course directory (ex. psyc1, spd1, marketing, etc) testing: For developer use only. Boolean used to indicate to use testing data. Value: &#39;video_axis&#39;: Dataframe containing video course structure information Examples: obtain_video_axis_data(input_course = &#39;psyc1&#39;) 13.1.4 write_wrangled_video_data 13.1.4.1 Main Documentation Outputs cleaned data as csv Description: Writes cleaned data as a csv into the course correct directory Usage: write_wrangled_video_data(input_course, cleaned_data, testing = FALSE) Arguments: input_course: Name of course directory (ex. psyc1, spd1, marketing, etc) cleaned_data: Dataframe containing cleaned data. This cleaned data is typically obtained through testing: For developer use only. Boolean used to indicate to use testing data. &#39;make_tidy_segments()&#39; Value: No return value Examples: write_wrangled_video_data(input_course = &#39;psyc1&#39;, cleaned_data=start_end_df) 13.1.5 prepare_video_data 13.1.5.1 Main Documentation Converts columns into proper variable types and adds additional columns with video information Description: Additional columns added: - &#39;max_stop_times&#39;: proxy for video length - &#39;course_order&#39;: occurrence of video within course structure - &#39;index_chapter&#39;: occurrence of chapter within course structure - &#39;chapter_name&#39;: name of chapter Usage: prepare_video_data(video_data, video_axis) Arguments: video_axis: A dataframe containing course structure information. Contains columns course_order, index_chapter, chapter_name data: Raw input dataframe to be transformed. &#39;data&#39; is obtained through &#39;obtain_raw_video_data()&#39; Value: &#39;prepared_data&#39;: The prepared data with converted variable types and extra columns Examples: prepare_video_data(data) 13.1.6 get_start_end_df 13.1.6.1 Main Documentation Obtains start and end times for video events Description: Parses dataframe and adds columns &#39;start&#39; and &#39;end&#39; showing the start and end time that a user watched a video Usage: get_start_end_df(data) Arguments: data: Dataframe containing tracklog data of students. This is obtained typically through &#39;prepare_video_data()&#39; Value: &#39;start_end_df&#39;: Original dataframe with &#39;start&#39; and &#39;end&#39; columns Examples: get_start_end_df(data = data) 13.1.7 get_watched_segments 13.1.7.1 Main Documentation Returns original dataframe with segment columns Description: Returns original dataframe with segement columns. Segment columns are 0 if the segment is not located within the start and end values and 1 otherwise. Usage: get_watched_segments(data) Arguments: data: Dataframe containing start and end columns. This dataframe is typically obtained through &#39;get_start_end_df()&#39; Value: &#39;data&#39;: Original input dataframe with new segment columns Examples: get_watched_segments(data = start_end_df) 13.1.8 make_tidy_segments 13.1.8.1 Main Documentation Returns tidy (more useable) version of input dataframe Description: Returns a tidy, more usable, version of the input dataframe. Segment information is converted into a single column using &#39;gather()&#39; Usage: make_tidy_segments(data) Arguments: data: Dataframe containing segment information. This dataframe is typically obtained through &#39;get_watched_segments()&#39; Value: &#39;data&#39;: Tidy version of input dataframe. Examples: make_tidy_segments(data = start_end_df) 13.1.9 check_integrity 13.1.9.1 Main Documentation Checks to make sure start and end data passes sanity checks Description: Returns a boolean of whether or not start and end data makes sense. This checks for NA values, end times that are passed the maximum length of the video, and extremely long and short watch durations. The threshold for watch durations can be adjusted in the global constants: &#39;MIN_DURATION&#39; and &#39;MAX_DURATION&#39; Usage: check_integrity(start, end, max_stop_position) Arguments: start: Time into video that the user has started watching the video end: Time into the video that the user has stopped watching the video max_stop_position: Length of the video being watched Value: &#39;integrity&#39;: Boolean of whether or not the data passes integrity checks Examples: check_integrity(start, end, max_stop_position) 13.1.10 get_end_time 13.1.10.1 Main Documentation Calculates video end time for non-video events using time stamps Description: Calculates video end time for non-video events using time stamps Usage: get_end_time(start, time, time_ahead, latest_speed) Arguments: start: Time into video that the user has started watching the video time: Time stamp of when the user started watching the video time_ahead: Time stamp of next event following the play event latest_speed: The speed at which the user was watching the video Value: &#39;end&#39;: Time into video that the user has stopped watching Examples: get_end_time(start, time, time_ahead, latest_speed) 13.1.11 get_mode 13.1.11.1 Main Documentation Obtain most common value from list Description: Obtain most common value from list Usage: get_mode(x) Arguments: x: List containing integer values Value: &#39;mode&#39;: The most common value within the list Examples: get_mode(x=c(0,1,2,2,2,3)) 13.2 Server Functions 13.2.1 get_aggregated_df 13.2.1.1 Main Documentation Aggregates dataframe by video and segment Description: Aggregates input dataframe by video (video_id) and segment (min_into_video). Additionally, adds columns: - &#39;unique_views&#39;/&#39;`Students`&#39; (number of learners who started the video), - &#39;watch_rate&#39;/&#39;`Views per Student`&#39; (number of students who have watched the segment divided by unique_views), - &#39;avg_watch_rate&#39; (average of watch_rate per video) - &#39;high_low&#39; (&#39;High Watch Rate&#39;, &#39;Low Watch Rate, or &#39;Normal&#39;) - &#39;up_until&#39; (1 if the average learner had watched up until the particular min_into_video, 0 if they had not) Usage: get_aggregated_df(filt_segs, top_selection) Arguments: filt_segs: Dataframe containing students that have been filtered by selected demographics. Typically obtained via &#39;filter_demographics()&#39; top_selection: Value of the number of top segments to highlight. Value: &#39;aggregate_segment_df&#39;: Aggregated dataframe with additional columns Examples: get_aggregated_df(filt_segs, 25) 13.2.1.2 Additional Notes: This function will read the filtered data frame version of the output csv file from wrangle_video. As an example, this function can be used in the following way: tidy_segment_df &lt;- read_csv(&quot;path/to/course/wrangled_video_heat.csv&quot;) filt_segs &lt;- filter_demographics(tidy_segment_df) aggregated_df &lt;- get_aggregated_df(filt_segs, 10) The high_low segment classification is based off a linear model (using lm) using the following features: course_order: Index of the video arranged by course structure min_into_video: How far into the video the segment is The up_until variable is simply obtained by looking at the maximum time that a video_stop event had occurred. As a consequence, if many students frequently skip to the end of the video without watching anything in between, this statistic may be misinterpreted. There are plans to change this in the future as it is very doable 13.2.2 get_ch_markers 13.2.2.1 Main Documentation Obtains locations of chapter lines to be placed on visualizations Description: Obtains locations of chapter lines to be placed on visualizations Usage: get_ch_markers(filt_segs) Arguments: filt_segs: Dataframe containing students that have been filtered by selected demographics. Typically obtained via &#39;filter_demographics()&#39; Value: &#39;ch_markers&#39;: List of values of where to place chapter lines on visualizations Examples: get_ch_markers(filt_segs) 13.2.3 get_video_lengths 13.2.3.1 Main Documentation Obtains dataframe with length of videos Description: Obtains dataframe with length of videos Usage: get_video_lengths(filt_segs) Arguments: filt_segs: Dataframe containing students that have been filtered by selected demographics. Typically obtained via &#39;filter_demographics()&#39; Value: &#39;vid_lengths&#39;: Dataframe with the video lengths associated with each video ID. Examples: get_video_lengths(filt_segs) 13.2.4 get_summary_table 13.2.4.1 Main Documentation Obtains locations of chapter lines to be placed on visualizations Description: Obtains locations of chapter lines to be placed on visualizations Usage: get_ch_markers(filt_segs) Arguments: filt_segs: Dataframe containing students that have been filtered by selected demographics. Typically obtained via &#39;filter_demographics()&#39; Value: &#39;ch_markers&#39;: List of values of where to place chapter lines on visualizations Examples: get_ch_markers(filt_segs) 13.2.5 get_video_comparison_plot 13.2.5.1 Main Documentation Obtains heatmap plot comparing videos against each other Description: Obtains heatmap plot comparing videos against each other Usage: get_video_comparison_plot(filtered_segments, module, filtered_ch_markers) Arguments: filtered_segments: Dataframe of segments and corresponding watch counts filtered by demographics module: String of module (chapter) name to display filtered_ch_markers: List of values containing locations of where to put chapter markers Value: &#39;g&#39;: ggplot heatmap object Examples: get_video_comparison_plot(filtered_segments, module, filtered_ch_markers) 13.2.6 get_segment_comparison_plot 13.2.6.1 Main Documentation Obtains heatmap plot comparing segments against each other Description: Obtains heatmap plot comparing segments against each other Usage: get_segment_comparison_plot(filtered_segments, module, filtered_ch_markers) Arguments: filtered_segments: Dataframe of segments and corresponding watch counts filtered by demographics module: String of module (chapter) name to display filtered_ch_markers: List of values containing locations of where to put chapter markers Value: &#39;g&#39;: ggplot heatmap object Examples: get_segment_comparison_plot(filtered_segments, module, filtered_ch_markers) 13.2.7 get_top_hotspots_plot 13.2.7.1 Main Documentation Obtains heatmap with segments of highest watch rate highlighted Description: Obtains heatmap with segments of highest watch rate highlighted Usage: get_top_hotspots_plot(filtered_segments, module, filtered_ch_markers) Arguments: filtered_segments: Dataframe of segments and corresponding watch counts filtered by demographics module: String of module (chapter) name to display filtered_ch_markers: List of values containing locations of where to put chapter markers Value: &#39;g&#39;: ggplot heatmap object Examples: get_top_hotspots_plot(filtered_segments, module, filtered_ch_markers) 13.2.7.2 Additional Notes: This function is no longer used the plot was discarded after usability testing. 13.2.8 get_high_low_plot 13.2.8.1 Main Documentation Obtains heatmap plot highlighting which segments have abnormally high or low watch rates Description: Obtains heatmap plot highlighting which segments have abnormally high or low watch rates Usage: get_high_low_plot(filtered_segments, module, filtered_ch_markers) Arguments: filtered_segments: Dataframe of segments and corresponding watch counts filtered by demographics module: String of module (chapter) name to display filtered_ch_markers: List of values containing locations of where to put chapter markers Value: &#39;g&#39;: ggplot heatmap object Examples: get_high_low_plot(filtered_segments, module, filtered_ch_markers) 13.2.8.2 Additional Notes: This function returns a plot where segments with abnormally high and low watch rates are highlighted. “High” and “low” watch rates are determined by the residuals from a linear model obtained via lm Please see source code and documentation for get_aggregated_df for more details. 13.2.9 get_up_until_plot 13.2.9.1 Main Documentation Obtains heatmap plot highlighting which segment has been watched up until on average Description: Obtains heatmap plot highlighting which segment has been watched up until on average Usage: get_up_until_plot(filtered_segments, module, filtered_ch_markers) Arguments: filtered_segments: Dataframe of segments and corresponding watch counts filtered by demographics module: String of module (chapter) name to display filtered_ch_markers: List of values containing locations of where to put chapter markers Value: &#39;g&#39;: ggplot heatmap object Examples: get_up_until_plot(filtered_segments, module, filtered_ch_markers) 13.2.9.2 Additional Notes: This function returns a plot in which segments are highlighted up until the average maximum stop time per student. It should be noted that this diagram may be misleading. Please see documentation for get_aggregated_df for more details. 13.2.10 get_rank 13.2.10.1 Main Documentation Returns the ranking of a vector x Description: Returns the ranking of a vector x Usage: get_rank(x) Arguments: x: A vector of numeric values Value: &#39;g&#39;: The ranking of the values within x Examples: get_rank(c(10, 20, 20, 22, 5)) 13.2.10.2 Additional Notes: This function returns a data frame in which the the duration watched per minute video is calculated. This is calculated by (average time spent on video (minutes) by all learners who have started the video)/(length of video (minutes)) It should be noted that the average time spent on video is calculated via the count in which the segment has been watched multiplied by the segment length. As a result, if users are consistently only watching 3 seconds of a 20 second segment, this number may be artificially inflated. This is because if a student watches more than 1 second of a segment, it will count as a “view”/“count” of the segment. This 1 second threshold can be adjusted via adjusting the global constant MIN_DURATION found in the video_wrangling.R file. "],
["deployment-walkthrough.html", "14 Deployment Walkthrough 14.1 Step-by-step Guide", " 14 Deployment Walkthrough This is a guide for the remote deployment of the EdXViz dashboard. 14.1 Step-by-step Guide EdXViz is a Shiny server application that allows instructors and course designers to see how their students are interacting with their courses. For best results, this application should be run from a server and installed there. This step-by-step guide will you to set up such a server. Spin up a server instance. This process was tested on an Azure instance with 7 Gb of RAM and 7 Gb of space. The amount of RAM needed is a function of the number of concurrent users you expect and whether they are working on multiple courses. This setup was tested with six separate courses and there was no lag. SSH into your instance, Type git clone git@github.com:AndrewLim1990/mooc_capstone_public.git cd mooc_capstone This will clone the git repo. All the necessary code is included. sudo docker run --rm -ti -p 3838:3838 -v $(pwd):/srv/shiny-server --name=&quot;populate&quot; lstmemery/moocshiny bin/bash This will download and deploy the docker image. The image is about 2 gigabytes and contains the scripts to populate the course and run the server. cd srv/shiny-server/ conda env create -f environment.yml source activate mooc This creates and activates a virtual Python. environment in which courses can be populated. gcloud auth application-default login This grants access to Google BigQuery. Copy the URL into the browser and paste the result into the terminal. gcloud auth login nano .config.json .config.json defines which courses should be populated. Each entry should have A short_name (which defines it’s path on the site) A BigQuery table name A Google Cloud Storage table name (likely similar to the BigQuery name) cd r-package/exec/ python populate_courses.py This step can take a significant amount of time to complete, depending on the number of courses being populated. exit sudo docker rm -f populate sudo docker run -d -p 80:3838 -v ~/mooc_capstone_private/r-package/:/srv/shiny-server/ -v ~/mooc_capstone_private/docs/:/var/log/shiny-server/ lstmemery/moocshiny This runs the shiny server. "]
]
